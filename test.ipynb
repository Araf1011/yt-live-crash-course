{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "198ac0a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Suii\n"
     ]
    }
   ],
   "source": [
    "print(\"Suii\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45d1cca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ddd8a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84c8f30b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not OPENAI_API_KEY:\n",
    "    raise ValueError(\"OPENAI_API_KEY is missing in your .env\")\n",
    "os.environ[\"OPENAI_API_KEY\"] = OPENAI_API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a94c321b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc5d1ec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_llm = ChatOpenAI(model=\"gpt-4o-mini\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e54b549c",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_llm.invoke(\"Hello, how are you?\").content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59bc9d91",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing_extensions import TypedDict, Annotated\n",
    "import operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31678f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import AnyMessage, HumanMessage, AIMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d784b5bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphState(TypedDict):\n",
    "    messages: Annotated[list[AnyMessage], operator.add]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f52f2ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "{\n",
    "    \"messages\": [HumanMessage(content=\"Hi, this is Sunny. Say hello in detail.\")]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edd84742",
   "metadata": {},
   "outputs": [],
   "source": [
    "[\"hi\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec54a6cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "[\"hi\",\"how are you?\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7921966",
   "metadata": {},
   "outputs": [],
   "source": [
    "def llm_call(state: GraphState) -> dict:\n",
    "    \"\"\"Call the LLM using conversation messages and append AI response.\"\"\"\n",
    "    response = chat_llm.invoke(state[\"messages\"])  # AIMessage\n",
    "    return {\n",
    "        \"messages\": [response]\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dc6d044",
   "metadata": {},
   "outputs": [],
   "source": [
    "def token_counter(state: GraphState) -> dict:\n",
    "    \"\"\"Count tokens (simple word count) in the last AI message.\"\"\"\n",
    "    last_msg = state[\"messages\"][-1]\n",
    "    text = last_msg.content\n",
    "    token_number = len(text.split())\n",
    "    summary = f\"Total token number in the generated answer (word count) is {token_number}\"\n",
    "    return {\n",
    "        \"messages\": [AIMessage(content=summary)]\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f8fe5a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "062885de",
   "metadata": {},
   "outputs": [],
   "source": [
    "builder = StateGraph(GraphState)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "852f78c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "builder.add_node(\"llm_call\", llm_call)\n",
    "builder.add_node(\"token_counter\", token_counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd5e63b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "builder.set_entry_point(\"llm_call\")\n",
    "builder.add_edge(\"llm_call\", \"token_counter\")\n",
    "builder.set_finish_point(\"token_counter\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aaac655",
   "metadata": {},
   "outputs": [],
   "source": [
    "app = builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac150782",
   "metadata": {},
   "outputs": [],
   "source": [
    "app.get_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "732ab183",
   "metadata": {},
   "source": [
    "Graph(nodes={'__start__': Node(id='__start__', name='__start__', data=RunnableCallable(tags=None, recurse=True, explode_args=False, func_accepts={}), metadata=None), 'llm_call': Node(id='llm_call', name='llm_call', data=llm_call(tags=None, recurse=True, explode_args=False, func_accepts={}), metadata=None), 'token_counter': Node(id='token_counter', name='token_counter', data=token_counter(tags=None, recurse=True, explode_args=False, func_accepts={}), metadata=None), '__end__': Node(id='__end__', name='__end__', data=None, metadata=None)}, edges=[Edge(source='__start__', target='llm_call', data=None, conditional=False), Edge(source='llm_call', target='token_counter', data=None, conditional=False), Edge(source='token_counter', target='__end__', data=None, conditional=False)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63f24e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed06d8cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Image(app.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77cb29e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = app.invoke({\n",
    "    \"messages\": [HumanMessage(content=\"Hi, this is Sunny. Say hello in detail.\")]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82600b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6262072",
   "metadata": {},
   "outputs": [],
   "source": [
    "for m in result[\"messages\"]:\n",
    "    print(type(m).__name__, \":\", m.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1579d539",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
